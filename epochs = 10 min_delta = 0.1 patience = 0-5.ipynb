{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from IPython import display\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML\n",
    "from skimage.io import imread,imshow\n",
    "from skimage import measure,color,io,feature\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DL\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.optimizers import Adam\n",
    "import keras.utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "path='C:/Users/Bermuda/OneDrive/Workshop/Dataset'\n",
    "for fname in os.listdir(path):\n",
    "    print(fname,end=' ')\n",
    "    paths=path+'/'+str(fname)\n",
    "    for iname in os.listdir(paths):\n",
    "        #print(iname,end=' ')\n",
    "        pathss=paths+'/'+str(iname)\n",
    "        img=imread(pathss)\n",
    "        \n",
    "        img_gray=color.rgb2gray(img)\n",
    "        x.append(img_gray)\n",
    "        y.append(fname)\n",
    "        \n",
    "        img_rotate1=ndimage.rotate(img,90)\n",
    "        img_gray=color.rgb2gray(img)\n",
    "        x.append(img_gray)\n",
    "        y.append(fname)\n",
    "        \n",
    "        img_rotate2=ndimage.rotate(img,180)\n",
    "        img_gray=color.rgb2gray(img)\n",
    "        x.append(img_gray)\n",
    "        y.append(fname)\n",
    "        \n",
    "        img_rotate3=ndimage.rotate(img,270)\n",
    "        img_gray=color.rgb2gray(img)\n",
    "        x.append(img_gray)\n",
    "        y.append(fname)\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.30, random_state=507)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(x_train.shape[0], 21, replace=False)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns * rows + 1):\n",
    "    img = x_train[index[i]]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "x_train = x_train.reshape(532, 100, 100, 1)\n",
    "x_test = x_test.reshape(228, 100, 100, 1)\n",
    "\n",
    "# x_train /= 255  # normalize dataset\n",
    "# x_test /= 255\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(100, 100, 1))) #padding='same'ทำzero padding มาให้\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.save_weights('weights.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"epochs = 10 min_delta = 0.1 patience = 0\")\n",
    "\n",
    "model.load_weights('weights.h5py')\n",
    "es=keras.callbacks.EarlyStopping(monitor='acc',min_delta=0.1,patience=0,verbose=0,mode='auto')#min_delta=0.1,patience=5\n",
    "history=model.fit(x_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]) #epochs=15\n",
    "# saves the weights of the model as a HDF5 file\n",
    "model.save('my_model0.h5')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model train vs validation loss : \")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title(\"model train vs validation acc : \")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "loss,acc = model.evaluate(x_test,y_test)\n",
    "print(\"Acc = \" + str(acc))\n",
    "print(\"Loss = \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"epochs = 10 min_delta = 0.1 patience = 1\")\n",
    "\n",
    "model.load_weights('weights.h5py')\n",
    "es=keras.callbacks.EarlyStopping(monitor='acc',min_delta=0.1,patience=1,verbose=0,mode='auto')#min_delta=0.1,patience=5\n",
    "history=model.fit(x_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]) #epochs=15\n",
    "# saves the weights of the model as a HDF5 file\n",
    "model.save('my_model1.h5')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model train vs validation loss : \")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title(\"model train vs validation acc : \")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "loss,acc = model.evaluate(x_test,y_test)\n",
    "print(\"Acc = \" + str(acc))\n",
    "print(\"Loss = \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"epochs = 10 min_delta = 0.1 patience = 2\")\n",
    "\n",
    "model.load_weights('weights.h5py')\n",
    "es=keras.callbacks.EarlyStopping(monitor='acc',min_delta=0.1,patience=2,verbose=0,mode='auto')#min_delta=0.1,patience=5\n",
    "history=model.fit(x_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]) #epochs=15\n",
    "# saves the weights of the model as a HDF5 file\n",
    "model.save('my_model2.h5')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model train vs validation loss : \")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title(\"model train vs validation acc : \")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "loss,acc = model.evaluate(x_test,y_test)\n",
    "print(\"Acc = \" + str(acc))\n",
    "print(\"Loss = \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"epochs = 10 min_delta = 0.1 patience = 3\")\n",
    "\n",
    "model.load_weights('weights.h5py')\n",
    "es=keras.callbacks.EarlyStopping(monitor='acc',min_delta=0.1,patience=3,verbose=0,mode='auto')#min_delta=0.1,patience=5\n",
    "history=model.fit(x_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]) #epochs=15\n",
    "# saves the weights of the model as a HDF5 file\n",
    "model.save('my_model3.h5')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model train vs validation loss : \")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title(\"model train vs validation acc : \")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "loss,acc = model.evaluate(x_test,y_test)\n",
    "print(\"Acc = \" + str(acc))\n",
    "print(\"Loss = \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"epochs = 10 min_delta = 0.1 patience = 4\")\n",
    "\n",
    "model.load_weights('weights.h5py')\n",
    "es=keras.callbacks.EarlyStopping(monitor='acc',min_delta=0.1,patience=4,verbose=0,mode='auto')#min_delta=0.1,patience=5\n",
    "history=model.fit(x_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]) #epochs=15\n",
    "# saves the weights of the model as a HDF5 file\n",
    "model.save('my_model4.h5')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model train vs validation loss : \")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title(\"model train vs validation acc : \")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "loss,acc = model.evaluate(x_test,y_test)\n",
    "print(\"Acc = \" + str(acc))\n",
    "print(\"Loss = \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"epochs = 10 min_delta = 0.1 patience = 5\")\n",
    "\n",
    "model.load_weights('weights.h5py')\n",
    "es=keras.callbacks.EarlyStopping(monitor='acc',min_delta=0.1,patience=5,verbose=0,mode='auto')#min_delta=0.1,patience=5\n",
    "history=model.fit(x_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]) #epochs=15\n",
    "# saves the weights of the model as a HDF5 file\n",
    "model.save('my_model5.h5')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model train vs validation loss : \")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title(\"model train vs validation acc : \")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(['train','validation'],loc='upper right')\n",
    "plt.show( )\n",
    "loss,acc = model.evaluate(x_test,y_test)\n",
    "print(\"Acc = \" + str(acc))\n",
    "print(\"Loss = \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
